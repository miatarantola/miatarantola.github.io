{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d5bcfb8a-c21c-4b79-b72e-f5d90a43b49f",
   "metadata": {},
   "source": [
    "---\n",
    "title: Learning from Timnit Gebru\n",
    "author: Mia Tarantola\n",
    "date: '2023-04-16'\n",
    "\n",
    "description: \"A blog post relating to our talk with Timnit Gebru\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dc80e7-478a-40bb-a031-d7cc9d1da9ca",
   "metadata": {},
   "source": [
    "# Learning from Timnit Gebru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8add115-1398-48aa-b887-b94ec5b133c8",
   "metadata": {},
   "source": [
    "Mia Tarantola"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3093b0-4e78-4ab2-9c5b-91db0eefc2b0",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1432e72-b9f7-4cc5-aa3c-026e73521636",
   "metadata": {},
   "source": [
    "This blog post will contain two parts. The first portion will be completed prior to our talk and will be based on self guided research on our speaker Timnit Gebru. I will take notes and pose some thoughtful questions that I think will make for a good discussion.\n",
    "\n",
    "The second portion will be completed during/after Gebru's talk. I will take notes and reflect on the material.\n",
    "\n",
    "**Dr. Timnit Gebru is a successful American computer scientist who focuses on artificial intelligence and algorithmic bias. She has become a well known advocated for diversity in technology and even founded her own community , Black in AI. In December 2020 Gebru left her position as the Ethical Artificial Intelligence Team lead at Google, following pushback fron her as-yet unpuclished paper voicing her concerns on the dangerous biases of large language models.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313189b7-def1-4e1e-9e25-ae86413cc8e3",
   "metadata": {},
   "source": [
    "## Part 1: Questions for Dr. Gebru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924e986a-d86e-4311-b809-cf329a01edb5",
   "metadata": {},
   "source": [
    "### Notes of Dr. Grebru's talk: conference on Computer Vision and Pattern Recognition 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a63cafe-c9a7-43e8-92b2-370dec21ffff",
   "metadata": {},
   "source": [
    "[recording of the talk](https://www.youtube.com/watch?v=0sBE5OyD7fk&t=802s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f0adb7-5266-4f0f-be51-be08ff4707c6",
   "metadata": {},
   "source": [
    "Timnit Gebru's talk on \"Computer Vision in practice: who is benefitting and who is being harmed?\" focuses on the ethical ramifications of computer vision technology in our society. Grebru emphasizes the need for critical thought on the possible effects of new technologies on marginalized communities as a top researcher in artifical intelligence and ethics.\n",
    "\n",
    "Gebru's talk emphasizes the danger that can result from the use of computer vision technology when it is implemented without adequate consideration of the potential consequences. She discusses how face recognition technology may be used to mistakenly identify people based on their gender and skin color, potentially leading to false charges and arrests. Additionally, predictive policing systems that rely on biased data sets can perpetuate systemic discrimination against communities of color, leading to increased surveillance and targeting. The ethics of data collecting and utilization are also covered by Gebru. She emphasizes that a model's deployment might still be unethical even if its accuracy is identical among all groups. Images scraped from numerous online sources are frequently included in data sets, often without the subjects' knowledge. She says that people are unlikely to want their pictures to be used in face recognition software to identify protesters.\n",
    "\n",
    "Gebru argues that it is essential for individuals who create and use computer vision systems to take into account these possible negative effects and strive toward creating more open and accountable business processes. She stresses the importance of diversity and inclusion in the creation of moral and responsible AI systems. She also encourages businesses and decision-makers to give underrepresented populations' demands and worries first priority while developing and implementing computer vision technologies.\n",
    "\n",
    "Gebru's presentation serves as a reminder of the essential part AI practitioners and researchers must play in influencing the creation and use of computer vision technologies. We can progress toward developing AI systems that are beneficial to every member of society by considering the ethical implications of these systems and including a variety of viewpoints into their development.\n",
    "\n",
    "**TL;DR In order to create ethical and just predictive modeling systems, we need to prioritize the need for diverse and inclusive development and implementation practices.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ddee71-6e6c-4cf4-b1ba-61487c8c4db3",
   "metadata": {},
   "source": [
    "### Questions to ask Timnit Gebru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d632ca6-bdc6-4fe0-9ede-74bc19058353",
   "metadata": {},
   "source": [
    "- *How can we address the issue of biased data sets in computer vision technology, and what strategies can be used to prevent the continuation of systemic discrimination?*\n",
    "- *What role should companies and policymakers play in regulating the use of computer vision technology, and what policies and practices would you recommend?*\n",
    "- *Given the potential for danger/harm caused by computer vision technology, what ethical considerations should AI researchers keep in mind when designing and deploying these models?*\n",
    "- *Can you share any examples of organizations or initiatives that you believe are making progress in addressing the ethical implications of AI, and what we can learn from them?*\n",
    "- *How can we better educate the public about the ethical implications of computer vision technology, and what steps can be taken to increase awareness and engagement on this issue?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfada33f-8d82-43b8-8691-10a8ed7d8e00",
   "metadata": {},
   "source": [
    "## Notes on In-Class Talk/ Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa2fccd-23bc-40d1-bf05-d7506af01c2a",
   "metadata": {},
   "source": [
    "- *theft normalized*\n",
    "> - *scraping images - might not be an image peeople want taken*\n",
    "> - *procarious workforce that can't advocate for themselves *\n",
    "> > - *people are scared to lose opportunities*\n",
    "> - *lack of enforcement, copyright etc*\n",
    "\n",
    "Independent research org vs larger tech companies\n",
    "- *She was fired when she spoke out at a larger tech companies*\n",
    "- *People are too scared to say anything at companies like google*\n",
    "- *her company to beholden to that incentive*\n",
    "- *She still has to fundraise for her institute*\n",
    "- *Not only her job on the line but also everyone that works at the institution*\n",
    "- *Can create an environment where people can have diverse ideas*\n",
    "- *Silence no more act - illegal for people to enforce NDA in cases of harrassment, bullying, discrimination --> easier for people to speak up*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68ba88d-66eb-478a-a06a-c1caa61f410d",
   "metadata": {},
   "source": [
    "seen any imporvements since talk?\n",
    "- *hard to change names of NIPS conference, close to porn site name, so much backlash*\n",
    "- *every little change is so contentous*\n",
    "- *resistance: GLAZE artist can run their artwork through this software before posting online, confuses ML models so they cannot copy this work*\n",
    "> - *worked with many artists*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2686b25-eb63-4263-8c09-e7c009f8989f",
   "metadata": {},
   "source": [
    "Mitigating bias - ways in use cases of computer vision that actively combat discrimination/bias\n",
    "- *forensic lab at NYU, connects protest bombs/weapons to certain companies*\n",
    "- *costa-rica conservation work: plant identification*\n",
    "- *YOLO - announced his leave from computer vision, cannot ignore the military applications anymore*\n",
    "- *1% good does not outweight the 99% bad use cases*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d93193b-4ddb-4783-8700-d6f956a7d359",
   "metadata": {},
   "source": [
    "very few people who are black and women in CV community - ever felt imposter syndrome\n",
    "- *seeing unqualified men, man created cult with no educational background - supporter of airstrikes*\n",
    "- *no imposter syndrome, people make you feel like that - sexism, racism*\n",
    "- *see how many unqualified people --> drop imposter syndrome*\n",
    "- *when in enviroments that are waiting for her to fail, then she feels it*\n",
    "- *about environment and what it instills in you*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca6587e-bec7-472b-b693-83956cf0b39e",
   "metadata": {},
   "source": [
    "## Notes on night talk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfbfcae-6774-4b50-9af2-40f86e4b0990",
   "metadata": {},
   "source": [
    "- founded DAR Institute\n",
    "- mitigating dangers of AI\n",
    "- imagining/executing a better tech future\n",
    "\n",
    "- millions of exploited workers that are fueling these AI projects\n",
    "> - chat GPT moderator suffering from trauma and PTSD\n",
    "\n",
    "Utopia for whom?\n",
    "- AGI = artificial general intelligence\n",
    "> - AI that outperforms humans (smart, well educated human)\n",
    "- rootes in eugenics\n",
    "> - not progressive movement\n",
    "- eugenics never went away, even after WWII\n",
    "- focus on \"improving the human stock\"\n",
    "> - get rid of undesirable traits/people : negative view\n",
    "> - give people the ability to deisgn their children --> design more intelligent kids\n",
    "> - tell desirable people to reproduce more\n",
    "- Second wave eugenics\n",
    "> - post human: a new superior species can be created\n",
    "> - legacy humans: everyone else (less desirable)\n",
    "> - intelligence explosion\n",
    "\n",
    "cosmism\n",
    "- humans will merge with technology\n",
    "- develop sentient AI and mind uploading technology\n",
    "\n",
    "TESCREAL bundle\n",
    "- historical roots\n",
    "- transcending humanism\n",
    "- Galton - make parents take intelligence exam before reproducing\n",
    "- some people advocating to harm researchers to stop AI apocalypse\n",
    "\n",
    "Discriminatory view\n",
    "- Bostrom: \"Blacks are more stupid than whites\"\n",
    "> - too many people with lower IQ reproducing too much --> new species\n",
    "- Pelvitz: below an IQ of 120, 0 points\n",
    "- influence\n",
    "> - all billionaires in movements (Elon Musk, etc) donating \n",
    "> - after the 70s researchers dissociate from AI --> lean more towards ML, CV, NLP\n",
    "- Deep mind founded and then bought by Google\n",
    "- Open AI --> Microsoft\n",
    "\n",
    "AGI Utopia\n",
    "- AGI will be so intelligent that it can figure out a solution/what to do to any scenario\n",
    "- morally superior AGI enhanced transhuman minds benefitting\n",
    "\n",
    "AGI Utopia for who?\n",
    "- \" On the dangers of stochastic parents...\"\n",
    "- text to image models - used for deep fakes, overly sexualizing women, harrasment campaigns\n",
    "- resources not going to organizations around the world who serve their own communities, goes to just one community\n",
    "> - poor people get AI doctors, ruch get humans\n",
    "\n",
    "No language left behind\n",
    "- investor pull out of smaller companies\n",
    "- larger companies often use a data set that is an output of another dataset = training on test data = NO!\n",
    "- NLLB doing much worse than ghana NLP\n",
    "\n",
    "AGI Apocalypse\n",
    "- TESCREALists argue probability of existential risk --> any event that would destroy our chances of creating utopia happening this century = high\n",
    "- morally obliged to create AGI Utopia and prevent AGI Apocalypse\n",
    "- Anthromorphising artifcats allows builders to avoid accountability\n",
    "- depply religous --> everlasting life\n",
    "\n",
    "unsafe and unscientific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c70d69-fdb2-486b-b832-2a5d50a66930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-0451] *",
   "language": "python",
   "name": "conda-env-ml-0451-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
